import transformers.utils.import_utils
import transformers.modeling_utils

# Monkey-patch to bypass strict torch version check (we are on torch 2.2.2)
# Must be done BEFORE any other transformers imports
transformers.utils.import_utils.check_torch_load_is_safe = lambda: None
transformers.modeling_utils.check_torch_load_is_safe = lambda: None

import torch
from transformers import pipeline
import nltk
from nltk.sentiment.vader import SentimentIntensityAnalyzer
from termcolor import cprint

class CryptoSentimentEnsemble:
    def __init__(self, use_gpu: bool = True):
        """
        åˆå§‹åŒ–ä¸‰ä¸ªæƒ…æ„Ÿåˆ†æžæ¨¡åž‹ã€‚
        """
        # 0. ç¡¬ä»¶æ£€æµ‹
        self.device = 0 if use_gpu and torch.cuda.is_available() else -1
        cprint(f"ðŸ¤– Loading sentiment models on device: {'GPU' if self.device == 0 else 'CPU'}...", "cyan")

        # 1. åˆå§‹åŒ– VADER (éœ€ä¸‹è½½è¯å…¸)
        try:
            nltk.data.find('sentiment/vader_lexicon.zip')
        except LookupError:
            nltk.download('vader_lexicon', quiet=True)
        self.vader = SentimentIntensityAnalyzer()

        # 2. åˆå§‹åŒ– Twitter-roBERTa (é€šç”¨ç¤¾åª’è¯­å¢ƒ)
        # model_id: cardiffnlp/twitter-roberta-base-sentiment-latest
        # Labels: positive, neutral, negative
        cprint("   Loading Twitter-roBERTa...", "cyan")
        self.roberta_pipe = pipeline(
            "sentiment-analysis",
            model="cardiffnlp/twitter-roberta-base-sentiment-latest",
            tokenizer="cardiffnlp/twitter-roberta-base-sentiment-latest",
            top_k=None, # è¿”å›žæ‰€æœ‰æ ‡ç­¾æ¦‚çŽ‡
            device=self.device
        )

        # 3. åˆå§‹åŒ– CryptoBERT (åŠ å¯†è´§å¸è¯­å¢ƒ)
        # model_id: ElKulako/cryptobert
        # Labels: Bullish, Neutral, Bearish
        cprint("   Loading CryptoBERT...", "cyan")
        self.crypto_pipe = pipeline(
            "sentiment-analysis",
            model="ElKulako/cryptobert",
            tokenizer="ElKulako/cryptobert",
            top_k=None, # è¿”å›žæ‰€æœ‰æ ‡ç­¾æ¦‚çŽ‡
            device=self.device
        )
        cprint("âœ¨ All sentiment models loaded successfully.", "green")

    def _normalize_transformer_output(self, results, pos_labels, neg_labels):
        """
        æ ¸å¿ƒé€»è¾‘ï¼šå°† Transformer æ¦‚çŽ‡åˆ†å¸ƒè½¬æ¢ä¸º [-1, 1] æ ‡é‡ã€‚
        Formula: Score = P(Positive) - P(Negative)
        """
        # results ç»“æž„ç¤ºä¾‹: [{'label': 'positive', 'score': 0.9}, {'label': 'negative', 'score': 0.05}...]
        # Flatten list of lists if necessary (pipeline sometimes returns list of lists for single input)
        if isinstance(results, list) and len(results) > 0 and isinstance(results[0], list):
            results = results[0]
            
        scores_map = {item['label']: item['score'] for item in results}
        
        # èŽ·å–æ­£å‘æ¦‚çŽ‡ (sumå¤„ç†æ˜¯ä¸ºäº†é˜²æ­¢æ¨¡åž‹è¾“å‡ºå¤šæ ‡ç­¾å˜ä½“ï¼Œè™½ä¸å¸¸è§ä½†ä½œä¸ºé˜²å¾¡æ€§ç¼–ç¨‹)
        p_pos = sum(scores_map.get(l, 0.0) for l in pos_labels)
        
        # èŽ·å–è´Ÿå‘æ¦‚çŽ‡
        p_neg = sum(scores_map.get(l, 0.0) for l in neg_labels)
        
        return p_pos - p_neg

    def analyze(self, text: str, weights: dict = None):
        """
        æ‰§è¡Œå¤šæ¨¡åž‹åˆ†æžå¹¶åŠ æƒã€‚
        é»˜è®¤æƒé‡: CryptoBERT(0.5) + roBERTa(0.3) + VADER(0.2)
        """
        if weights is None:
            weights = {'crypto': 0.5, 'roberta': 0.3, 'vader': 0.2}

        # --- A. VADER ---
        # compound å·²ç»æ˜¯ -1 åˆ° 1
        vader_score = self.vader.polarity_scores(text)['compound']

        # --- B. Twitter-roBERTa ---
        # æˆªæ–­è¿‡é•¿æ–‡æœ¬ä»¥é˜²æŠ¥é”™ (BERTé™åˆ¶512 tokens)
        # Pipeline handles truncation usually, but explicit slicing is safer for very long text
        roberta_raw = self.roberta_pipe(text[:2000], truncation=True)
        # Pipeline returns a list (one per input text), we sent one text
        if isinstance(roberta_raw, list) and isinstance(roberta_raw[0], list):
             roberta_raw = roberta_raw[0]
             
        roberta_score = self._normalize_transformer_output(
            roberta_raw, 
            pos_labels=['positive'], 
            neg_labels=['negative']
        )

        # --- C. CryptoBERT ---
        crypto_raw = self.crypto_pipe(text[:2000], truncation=True)
        if isinstance(crypto_raw, list) and isinstance(crypto_raw[0], list):
             crypto_raw = crypto_raw[0]

        crypto_score = self._normalize_transformer_output(
            crypto_raw, 
            pos_labels=['Bullish'], 
            neg_labels=['Bearish']
        )

        # --- D. åŠ æƒè®¡ç®— ---
        final_score = (
            (crypto_score * weights['crypto']) +
            (roberta_score * weights['roberta']) +
            (vader_score * weights['vader'])
        )

        return {
            "text_snippet": text[:50] + "..." if len(text) > 50 else text,
            "final_score": round(final_score, 4),
            "breakdown": {
                "crypto_bert": round(crypto_score, 4),
                "twitter_roberta": round(roberta_score, 4),
                "vader": round(vader_score, 4)
            },
            "raw_probabilities": {
                "roberta": roberta_raw,
                "crypto": crypto_raw
            }
        }
